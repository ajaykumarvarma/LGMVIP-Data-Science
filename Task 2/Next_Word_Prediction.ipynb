{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1G3kwAfVvGr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq\n",
        "import regex\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-uhlOfmX8mV",
        "outputId": "e1c06928-67a3-42dc-af7a-84ce940aa090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "path = \"/content/drive/MyDrive/1661-0.txt\"\n",
        "text = open(path).read().lower()"
      ],
      "metadata": {
        "id": "GMQEROuOc3E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Preprocessing\n",
        "character = sorted(list(set(text)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(character))\n",
        "indices_char = dict((i, c) for i, c in enumerate(character))\n",
        " \n",
        "print(f'unique chars: {len(character)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqdQNZ1idNxY",
        "outputId": "b4764807-5063-4f91-9dc2-a05ebe592c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique chars: 73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chunk 40 characters with 3 sequences\n",
        "seq_len = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - seq_len, step):\n",
        "    sentences.append(text[i: i + seq_len ])\n",
        "    next_chars.append(text[i + seq_len])\n",
        "print(f'num training examples: {len(sentences)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BBVVchtqL2R",
        "outputId": "f9f6a02e-172b-4674-fa06-a8d4903cafcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num training examples: 193950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generating our features and labels\n",
        "#one hot encoding\n",
        "X = np.zeros((len(sentences), seq_len, len(character)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(character)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "sentences[124]\n",
        "next_chars[100]"
      ],
      "metadata": {
        "id": "zX10-2LOdg0H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "50245c57-68d1-4a6c-ec55-b625c5cde3e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2f2383d5361d>:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X = np.zeros((len(sentences), seq_len, len(character)), dtype=np.bool)\n",
            "<ipython-input-7-2f2383d5361d>:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences), len(character)), dtype=np.bool)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoded data\n",
        "X[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgW4Lrkegzm4",
        "outputId": "b36b3b31-e87b-4917-bfb0-01bc5858e64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "        True])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "K69M3wTwqmZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d41a1b1-a37b-43a6-f58f-6ddbb30284d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(193950, 40, 73)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIndk6v9qp1-",
        "outputId": "762978dc-c387-414d-eee5-1c62f19aa3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True False False ... False False False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(seq_len, len(character))))\n",
        "model.add(Dense(len(character)))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfiYzy6aqwF2",
        "outputId": "811ded17-2945-49d2-e7c7-da61d787c05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_13 (LSTM)              (None, 256)               337920    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 73)                18761     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 73)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 356,681\n",
            "Trainable params: 356,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training our model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=25,monitor='val_loss',restore_best_weights=True)\n",
        "history = model.fit(X, y,\n",
        "                    validation_split=0.01, \n",
        "                    batch_size=128,\n",
        "                    epochs=50, \n",
        "                    shuffle=True,callbacks=[early_stopping_cb]).history"
      ],
      "metadata": {
        "id": "2WugvLRHisdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f43ebf9-be32-460c-9126-a162db415250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1501/1501 [==============================] - 14s 8ms/step - loss: 2.0685 - accuracy: 0.3945 - val_loss: 2.1906 - val_accuracy: 0.3825\n",
            "Epoch 2/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.6359 - accuracy: 0.5054 - val_loss: 1.9843 - val_accuracy: 0.4376\n",
            "Epoch 3/50\n",
            "1501/1501 [==============================] - 11s 8ms/step - loss: 1.5018 - accuracy: 0.5417 - val_loss: 1.9150 - val_accuracy: 0.4531\n",
            "Epoch 4/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.4290 - accuracy: 0.5615 - val_loss: 1.8420 - val_accuracy: 0.4851\n",
            "Epoch 5/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.3772 - accuracy: 0.5737 - val_loss: 1.8588 - val_accuracy: 0.4830\n",
            "Epoch 6/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.3426 - accuracy: 0.5814 - val_loss: 1.8796 - val_accuracy: 0.4758\n",
            "Epoch 7/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.3184 - accuracy: 0.5876 - val_loss: 1.8619 - val_accuracy: 0.4964\n",
            "Epoch 8/50\n",
            "1501/1501 [==============================] - 12s 8ms/step - loss: 1.2965 - accuracy: 0.5932 - val_loss: 1.9320 - val_accuracy: 0.4696\n",
            "Epoch 9/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.2778 - accuracy: 0.5992 - val_loss: 1.8869 - val_accuracy: 0.4938\n",
            "Epoch 10/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.2612 - accuracy: 0.6025 - val_loss: 1.9203 - val_accuracy: 0.4835\n",
            "Epoch 11/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.2503 - accuracy: 0.6055 - val_loss: 1.9358 - val_accuracy: 0.4840\n",
            "Epoch 12/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.2400 - accuracy: 0.6075 - val_loss: 1.9561 - val_accuracy: 0.4851\n",
            "Epoch 13/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.2310 - accuracy: 0.6100 - val_loss: 2.1337 - val_accuracy: 0.4613\n",
            "Epoch 14/50\n",
            "1501/1501 [==============================] - 11s 8ms/step - loss: 1.2300 - accuracy: 0.6114 - val_loss: 2.0205 - val_accuracy: 0.4856\n",
            "Epoch 15/50\n",
            "1501/1501 [==============================] - 11s 8ms/step - loss: 1.2287 - accuracy: 0.6102 - val_loss: 2.0840 - val_accuracy: 0.4778\n",
            "Epoch 16/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.2098 - accuracy: 0.6145 - val_loss: 2.0497 - val_accuracy: 0.4814\n",
            "Epoch 17/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.2078 - accuracy: 0.6172 - val_loss: 2.0478 - val_accuracy: 0.4825\n",
            "Epoch 18/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.2137 - accuracy: 0.6136 - val_loss: 2.0920 - val_accuracy: 0.4835\n",
            "Epoch 19/50\n",
            "1501/1501 [==============================] - 11s 8ms/step - loss: 1.2755 - accuracy: 0.5983 - val_loss: 2.1040 - val_accuracy: 0.4758\n",
            "Epoch 20/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.2207 - accuracy: 0.6123 - val_loss: 2.1004 - val_accuracy: 0.4928\n",
            "Epoch 21/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.1963 - accuracy: 0.6197 - val_loss: 2.1034 - val_accuracy: 0.4820\n",
            "Epoch 22/50\n",
            "1501/1501 [==============================] - 11s 8ms/step - loss: 1.1924 - accuracy: 0.6197 - val_loss: 2.1077 - val_accuracy: 0.4799\n",
            "Epoch 23/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.1998 - accuracy: 0.6174 - val_loss: 2.0993 - val_accuracy: 0.4789\n",
            "Epoch 24/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.2056 - accuracy: 0.6162 - val_loss: 2.9735 - val_accuracy: 0.3603\n",
            "Epoch 25/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.5398 - accuracy: 0.5303 - val_loss: 2.2343 - val_accuracy: 0.4423\n",
            "Epoch 26/50\n",
            "1501/1501 [==============================] - 11s 8ms/step - loss: 1.3255 - accuracy: 0.5831 - val_loss: 2.1364 - val_accuracy: 0.4753\n",
            "Epoch 27/50\n",
            "1501/1501 [==============================] - 11s 8ms/step - loss: 1.2510 - accuracy: 0.6035 - val_loss: 2.1725 - val_accuracy: 0.4665\n",
            "Epoch 28/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.2157 - accuracy: 0.6136 - val_loss: 2.1731 - val_accuracy: 0.4861\n",
            "Epoch 29/50\n",
            "1501/1501 [==============================] - 11s 7ms/step - loss: 1.2075 - accuracy: 0.6160 - val_loss: 2.2358 - val_accuracy: 0.4892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation\n",
        "loss_and_acc=model.evaluate(X,y)\n",
        "print(\"Test Loss\", loss_and_acc[0])\n",
        "print(\"Test Accuracy\", loss_and_acc[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iXLx2KSq3qm",
        "outputId": "84d69f4c-bf08-4e58-c749-107d4e30a39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6061/6061 [==============================] - 22s 4ms/step - loss: 1.2741 - accuracy: 0.6089\n",
            "Test Loss 1.2740947008132935\n",
            "Test Accuracy 0.6089301109313965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_input(text):\n",
        "    x = np.zeros((1, seq_len, len(character)))\n",
        "    for t, char in enumerate(text):\n",
        "        x[0, t, char_indices[char]] = 1.\n",
        "        \n",
        "    return x"
      ],
      "metadata": {
        "id": "g4I6DUZc5f_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#functions to get next probable characters\n",
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    \n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
      ],
      "metadata": {
        "id": "8nWVl1lMrRJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_completion(text):\n",
        "    original_text = text\n",
        "    generated = text\n",
        "    completion = ''\n",
        "    while True:\n",
        "        x = prepare_input(text)\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds, top_n=1)[0]\n",
        "        next_char = indices_char[next_index]\n",
        "        text = text[1:] + next_char\n",
        "        completion += next_char\n",
        "        \n",
        "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
        "            return completion\n",
        "def predict_completions(text, n=3):\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]            "
      ],
      "metadata": {
        "id": "GR1Va1Km4znc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction\n",
        "quotes = [   \n",
        "    \"it is nothing but correct prediction by the model and got average accuracy.\",\n",
        "    \"They work well for natural language processing tasks such as next word predi.\",\n",
        "    \"The sequences are then padded to ensure they have the same length.\",\n",
        "    \"After training, the accuracy of the model on the training data can be evaluated.\",\n",
        "    \"Model was trained with long short term memory rnn.\"  \n",
        "    \n",
        "]"
      ],
      "metadata": {
        "id": "k-HNRQYs44gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/nextword.h5\")"
      ],
      "metadata": {
        "id": "UR0V_Xn6ARW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"/content/drive/MyDrive/nextword.h5\")"
      ],
      "metadata": {
        "id": "0LucZ1lLT8Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_O1ShUfUNXH",
        "outputId": "1ca7f305-992a-4e28-b272-69bfc108600c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_13 (LSTM)              (None, 256)               337920    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 73)                18761     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 73)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 356,681\n",
            "Trainable params: 356,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for q in quotes:\n",
        "    seq = q[:40].lower()\n",
        "    print(seq)\n",
        "    print(predict_completions(seq, 5))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR82HZ7VUQFu",
        "outputId": "1e570cf0-5ccf-4cdf-95c3-1507dfd5ae09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it is nothing but correct prediction by \n",
            "['the ', 'a ', 'some ', 'my ', 'his ']\n",
            "\n",
            "they work well for natural language proc\n",
            "['ised ', 'essible ', 'less ', 'onted ', 'ate ']\n",
            "\n",
            "the sequences are then padded to ensure \n",
            "['the ', 'and ', 'which ', 'of ', 'in ']\n",
            "\n",
            "after training, the accuracy of the mode\n",
            "[' that ', 'n ', 'd ', '. ', 'r ']\n",
            "\n",
            "model was trained with long short term m\n",
            "['an ', 'e ', 'ore ', 'inutes ', 'y ']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cfv2OeEQUhOE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}